<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Documentation for the  NavWareSet dataset">
  <meta property="og:title" content="NavWareSet"/>
  <meta property="og:description" content="Documentation for the  NavWareSet dataset"/>
  <meta property="og:url" content="https://anr-navware.github.io/navwareset/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Social navigation human-robot interaction dataset socially compliant navigation non-compliant navigation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>NavWareSet</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    a:hover {
      text-decoration: underline;
    }
    /* Style the <details> container */
    details.expandable {
      border: 1px solid #dbdbdb;  /* Bulma light gray */
      border-radius: 4px;
      padding: 0.75em 1em;
      margin-top: 1em;
      background: #fafafa; /* Bulma's lightest background */
      transition: box-shadow 0.3s;
    }

    /* Add subtle shadow on hover/open */
    details.expandable[open] {
      box-shadow: 0 2px 6px rgba(10,10,10,0.1);
    }

    /* Style the summary toggle */
    details.expandable summary {
      cursor: pointer;
      font-weight: 600;
      outline: none;
      list-style: none;
    }

    /* Optional: add a custom disclosure icon */
    details.expandable summary::marker {
      display: none;
    }

    details.expandable summary::before {
      content: "▶ ";
      display: inline-block;
      transform: rotate(0deg);
      transition: transform 0.2s ease;
    }

    /* Rotate the icon when open */
    details.expandable[open] summary::before {
      transform: rotate(90deg);
    }

    /* Content inside */
    details.expandable .content {
      margin-top: 0.75em;
      padding-left: 1.5em;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">NavWareSet: A Dataset of Socially Compliant and Non-Compliant Robot Navigation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
               <!--
              <span class="author-block">
                
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Johnata Brayan</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Sihao Deng</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Armando Alves Neto</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Iaroslav Okunevich</a><sup>2</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Tomas Krajnik</a><sup>3</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Francois Bremond</a><sup>4</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Zhi Yan</a><sup>2,5</sup></span>
                  -->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!--
                    <span class="author-block">
                      <sup>1</sup>Universidade Federal de Minas Gerais<br>
                      <sup>2</sup>Université de technologie de Belfort Montbéliard<br>
                      <sup>3</sup>Czech Technical University in Prague<br>
                      <sup>4</sup>Inria<br>
                      <sup>5</sup>ENSTA - Institut Polytechnique de Paris<br>
                    </span>
                  -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://github.com/anr-navware" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-chalkboard-teacher"></i>
                        </span>
                        <span>Tutorials</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://search-data.ubfc.fr/FR-13002091000019-2025-05-22" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-download"></i>
                      </span>
                      <span>Downloads</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/anr-navware" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Repo</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/hero_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <strong>Top-left</strong>: Lidar point cloud of the robot's environment;<br>
        <strong>Top-right</strong>: Robot's own sensory data;<br>
        <strong>Bottom-left</strong>: Synced point cloud with pedestrian's positions and robot's pose;<br>
        <strong>Bottom-right</strong>: Extracted pedestrian and robot trajectories with environment map.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            NavWareSet is a novel dataset designed to advance socially aware robot navigation. It offers multi-modal recordings of socially compliant and non-compliant robot trajectories in realistic indoor scenarios. Using two different robots across seven diverse setups, NavWareSet captures rich human-robot interactions and navigation challenges. With lidar, RGB-D, video, odometry, and annotated human positions, it provides a valuable source for analyzing and training navigation algorithms that prioritize human comfort and safety.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Dataset overview -->
<section class="hero is-small">
   <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Overview</h2>
      <!-- unordered html list below -->
      <div class="content">
        <ul>
          <li>Wide range of social navigation scenarios with both individual and group interactions.</li>
          <li>Over 192 minutes of interaction data and over 172 minutes of annotated trajectories.</li>
          <li>Over XXX individualy annotated tracks.</li>
          <li>Sensory data from the perspective 2 different robots (Toyota HSR and Clearpath Jackal).</li>
          <li>Stationary groundtruth recording station (grs) with video camera and 3D LiDAR scans.</li>
          <li>Occupancy grid of the obstacles in the environment.</li>
          <li>Recording of both social and non-social behavior of the robots.</li>
        </ul>

    </div>
  </div>
</section>
<!-- End dataset overview -->

<!-- Experimental Setup -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Experimental Setup</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
              <!-- Setup section -->
              <p style="font-size: 1.5em; text-align: center; ">
                <strong>Environment</strong>
              </p>
            <div style="display: flex; gap: 16px; align-items: center;">
              <div style="flex: 1;">
                <!-- add image below-->
                <img src="static/images/map.png" alt="Experimental Setup" style="width: 100%; height: auto; border-radius: 8px;">
              </div>
              <p style="flex: 1;">
                The dataset was recorded in a broad garage space measuring 3.9 m × 10.7 m with a
                lateral opening making it possible to elicit tracks in a straight line or around corners.
                The environment is equipped with a ground truth recording station (grs) that includes a video
                recorder and a 3D LiDAR scanner. For each scene goal positions were placed around the map acording to
                different social navigation scenarios.

              </p>
            </div>
            <!-- end of Setup section -->

            <!-- Setup section -->
              <p style="font-size: 1.5em; text-align: center;">
                <br><strong>Groundtruth recording station (grs)</strong>
              </p>
            <div style="display: flex; gap: 16px; align-items: stretch;">
              <div style="flex: 1; display: flex; flex-direction: column;">
                <!-- add image below-->
                <img src="static/images/grs.jpg" alt="Experimental Setup" style="width: 100%; height: 100%; border-radius: 8px; object-fit: cover; flex: 1;">
              </div>
              <div style="flex: 2; display: flex; flex-direction: column;">
                <iframe width="100%" height="100%" style="flex: 1; min-height: 300px;" title="angel.stl" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="clipboard-write; autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share src="https://thangs.com/model/1362968/embed?utm_source=embed"></iframe>
              </div>
            </div>
              <br>
              <p class="has-text-justified" style="text-align: center;">
                The Ground Truth Recording Station (GRS) is equipped with an 
                <a href="https://www.intelrealsense.com/depth-camera-d455/" target="_blank" style="color: #1a0dab;">Intel® RealSense™ Depth Camera D455</a> 
                and a 
                <a href="https://cdn.robosense.cn/20200723161715_42428.pdf" target="_blank" style="color: #1a0dab;">Robosense RS-LiDAR-16 3D LiDAR</a>. 
                Both sensors are mounted on a custom 3D-printed frame, which is positioned on a tripod for stable data collection. 
                You can interact with the structure in the 3D viewport above (click and drag to rotate) or access the 3D model 
                <a href="https://thangs.com/designer/johnatabrayan/3d-model/grs.stl-1362968" target="_blank" style="color: #1a0dab;">here</a>.
              </p>
              <p class="has-text-justified" style="text-align: center;">
                To minimize occlusions, the GRS was positioned at a height of 2.17&nbsp;m above the ground. 
                To enhance the resolution of the LiDAR data, the GRS was tilted 15° downward toward the area of interest.
              </p>
            <!-- end of Setup section -->

            <!-- Setup section -->
              <p style="font-size: 1.5em; text-align: center;">
                <br><strong>Robots</strong>
              </p>
            <div style="display: flex; gap: 16px; align-items: center;">
              <div style="flex: 1;">
                <!-- add image below-->
                <img src="static/images/robots.jpg" alt="Experimental Setup" style="width: 100%; height: auto; border-radius: 8px;">
              </div>
                <p style="flex: 1;">
                  The robots used in the NavWareSet dataset are the
                  <a href="https://clearpathrobotics.com/jackal-small-unmanned-ground-vehicle/" target="_blank" style="color: #1a0dab;">Clearpath Jackal</a> and the
                  <a href="https://www.toyota-europe.com/news/2018/toyota-expanding-robotics-research-in-europe" target="_blank" style="color: #1a0dab;">Toyota HSR</a>.
                  The Jackal is a small, rugged robot designed for outdoor and indoor environments, equipped with a 3D LiDAR sensor and an RGB-D camera.
                  The HSR is a versatile human-support robot capable of performing household tasks, featuring a manipulator arm, a mobile base, and various sensors for safe and intelligent interaction with people and objects.
                  In most scenarios both robots were teleoperated by a human operator, first in a socially aware manner, and then in a non-aware manner.
                </p>
            </div>
            <!-- Setup section -->
              <p style="font-size: 1.5em; text-align: center;">
                <br><strong>Experiment description</strong>
              </p>
            <div style="display: flex; gap: 16px; align-items: stretch;">
              <div style="flex: 1; display: flex; flex-direction: column;">
                <!-- add image below-->
                <img src="static/images/Experiment_description.png" alt="Experimental Setup" style="width: 100%; height: 100%; border-radius: 8px; object-fit: cover; flex: 1;">
              </div>
            </div>
              <br>
              <p class="has-text-justified" style="text-align: center;">
                The experiment was designed to capture common social navigation scenarios. These scenarios were proposed by Francis et al. in their paper, <a href="https://arxiv.org/pdf/2306.16740" target="_blank" style="color: #1a0dab;">Principles and Guidelines for Evaluating Social Robot Navigation Algorithms</a>. They serve not only to facilitate data collection but also to provide a standardized basis for evaluating the performance of social navigation algorithms. A detailed description of the scenarios used in NavWareSet is provided in the table below.
              </p>
              <details class="expandable">
                <summary> Show Scenarios Table</summary>
                <div class="content">
                  <table border="1" cellpadding="5" cellspacing="0">
                    <thead>
                      <tr>
                        <th>Scenario Name</th>
                        <th>Scenario Description</th>
                        <th>Geom. Layout</th>
                        <th>Scientific Purpose</th>
                        <th>Robot Task</th>
                        <th>Human Behavior</th>
                        <th>Ideal Outcome</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td>FRONTAL APPROACH</td>
                        <td>A pedestrian and robot approach head-on.</td>
                        <td>Passable Space</td>
                        <td>Pedestrian Interaction</td>
                        <td>Navigate A to B</td>
                        <td>Navigate B to A</td>
                        <td>Robot / humans pass</td>
                      </tr>
                      <tr>
                        <td>PEDESTRIAN OBSTRUCTION</td>
                        <td>A pedestrian blocks the robot's path.</td>
                        <td>Passable Space</td>
                        <td>Pedestrian Interaction</td>
                        <td>Navigate A to B</td>
                        <td>Block path</td>
                        <td>Robot stops or reroutes</td>
                      </tr>
                      <tr>
                        <td>BLIND CORNER</td>
                        <td>A robot and human meet at a blind corner.</td>
                        <td>Corner</td>
                        <td>Pedestrian Interaction</td>
                        <td>Navigate A to B</td>
                        <td>Navigate B to A</td>
                        <td>No collision / obstruction</td>
                      </tr>
                      <tr>
                        <td>PERPENDICULAR CROSSING</td>
                        <td>Person moves perpendicular to robot.</td>
                        <td>Intersection</td>
                        <td>Pedestrian Interaction</td>
                        <td>Navigate A to B</td>
                        <td>Navigate B to A</td>
                        <td>No collision / obstruction</td>
                      </tr>
                      <tr>
                        <td>FOLLOWING HUMAN</td>
                        <td>A robot follows a person.</td>
                        <td>Walking Space</td>
                        <td>Joint Navigation</td>
                        <td>Follow human</td>
                        <td>Lead robot</td>
                        <td>Robot follows person</td>
                      </tr>
                      <tr>
                        <td>CIRCULAR CROSSING</td>
                        <td>People and robot move in paths that intersect in the center of a circle</td>
                        <td>Passable Space</td>
                        <td>Crowd Navigation</td>
                        <td>Navigate A to B</td>
                        <td>Navigate B to A</td>
                        <td>No collision / smooth flow</td>
                      </tr>

                      <tr>
                        <td>OBJECT HANDOVER</td>
                        <td>A robot hands an object to a human.</td>
                        <td>Passable Space</td>
                        <td>Interactive Navigation</td>
                        <td>Deliver/Receive object</td>
                        <td>Deliver/Receive object</td>
                        <td>Human/Robot takes object</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </details>
              <br>
              <p class="has-text-justified" style="text-align: center;">
                In total 17 participants were asigned numbers and divided in 2 groups of 5 and 5 pairs.
                Each group performed all scenarios but the object handover scenario. All scenarios were recorded for 4 minutes.
                Most scenarios were performed with both robots, except for the object handover scenario which was only performed with the Toyota HSR.
                Most scenarios were recorded twice, once with the robot navigating in a socially compliant manner and once in a non-compliant manner.
                A detailed description of all recorded scenes used in NavWareSet is provided in the table below.
              </p>
              <details class="expandable">
                <summary> Show Scenes Table</summary>
                <div class="content">
                  <table border="1">
                    <thead>
                      <tr>
                        <th>N°</th>
                        <th>Name</th>
                        <th>Scenario</th>
                        <th>Robot</th>
                        <th>Robot Behavior</th>
                        <th>Group</th>
                        <th>Participants</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr><td>1</td><td>Scene 1</td><td>Frontal Approach</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>2</td><td>Scene 2</td><td>Pedestrian Obstruction</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>3</td><td>Scene 3</td><td>Blind Corner</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>4</td><td>Scene 4</td><td>Following Human</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>5</td><td>Scene 5</td><td>Perpendicular Crossing</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>6</td><td>Scene 6</td><td>Circular Crossing</td><td>HSR</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>7</td><td>Scene 8</td><td>Frontal Approach</td><td>HSR</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>8</td><td>Scene 9</td><td>Pedestrian Obstruction</td><td>HSR</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>9</td><td>Scene 10</td><td>Blind Corner</td><td>HSR</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>10</td><td>Scene 12</td><td>Perpendicular Crossing</td><td>HSR</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>11</td><td>Scene 13</td><td>Circular Crossing</td><td>HSR</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 4, 5</td></tr>
                      <tr><td>12</td><td>Scene 15</td><td>Frontal Approach</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>13</td><td>Scene 16</td><td>Pedestrian Obstruction</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>14</td><td>Scene 17</td><td>Blind Corner</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>15</td><td>Scene 18</td><td>Following Human</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>16</td><td>Scene 19</td><td>Perpendicular Crossing</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>17</td><td>Scene 20</td><td>Circular Crossing</td><td>Jackal</td><td>Social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>18</td><td>Scene 21</td><td>Frontal Approach</td><td>Jackal</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>19</td><td>Scene 22</td><td>Pedestrian Obstruction</td><td>Jackal</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>20</td><td>Scene 23</td><td>Blind Corner</td><td>Jackal</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>21</td><td>Scene 25</td><td>Perpendicular Crossing</td><td>Jackal</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>22</td><td>Scene 26</td><td>Circular Crossing</td><td>Jackal</td><td>Non-social</td><td>Group 1</td><td>1, 2, 3, 5, 6</td></tr>
                      <tr><td>23</td><td>Scene 27</td><td>Frontal Approach</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>24</td><td>Scene 28</td><td>Pedestrian Obstruction</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>25</td><td>Scene 29</td><td>Blind Corner</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>26</td><td>Scene 30</td><td>Following Human</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>27</td><td>Scene 31</td><td>Perpendicular Crossing</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>28</td><td>Scene 32</td><td>Circular Crossing</td><td>HSR</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>29</td><td>Scene 34</td><td>Frontal Approach</td><td>HSR</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>30</td><td>Scene 35</td><td>Pedestrian Obstruction</td><td>HSR</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>31</td><td>Scene 36</td><td>Blind Corner</td><td>HSR</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>32</td><td>Scene 38</td><td>Perpendicular Crossing</td><td>HSR</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>33</td><td>Scene 39</td><td>Circular Crossing</td><td>HSR</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>34</td><td>Scene 41</td><td>Frontal Approach</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>35</td><td>Scene 42</td><td>Pedestrian Obstruction</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>36</td><td>Scene 43</td><td>Blind Corner</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>37</td><td>Scene 44</td><td>Following Human</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>38</td><td>Scene 45</td><td>Perpendicular Crossing</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>39</td><td>Scene 46</td><td>Circular Crossing</td><td>Jackal</td><td>Social</td><td>Group 2</td><td>7, 8, 9, 10, 12</td></tr>
                      <tr><td>40</td><td>Scene 47</td><td>Frontal Approach</td><td>Jackal</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>41</td><td>Scene 49</td><td>Blind Corner</td><td>Jackal</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>42</td><td>Scene 51</td><td>Perpendicular Crossing</td><td>Jackal</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 11</td></tr>
                      <tr><td>43</td><td>Scene 52</td><td>Circular Crossing</td><td>Jackal</td><td>Non-social</td><td>Group 2</td><td>7, 8, 9, 10, 12</td></tr>
                      <tr><td>44</td><td>Scene 53</td><td>Object handover</td><td>HSR</td><td>Social</td><td>Pair 1</td><td>2, 8</td></tr>
                      <tr><td>45</td><td>Scene 54</td><td>Object handover</td><td>HSR</td><td>Social</td><td>Pair 2</td><td>1, 9</td></tr>
                      <tr><td>46</td><td>Scene 55</td><td>Object handover</td><td>HSR</td><td>Social</td><td>Pair 3</td><td>13, 14</td></tr>
                      <tr><td>47</td><td>Scene 56</td><td>Object handover</td><td>HSR</td><td>Social</td><td>Pair 4</td><td>4, 15</td></tr>
                      <tr><td>48</td><td>Scene 57</td><td>Object handover</td><td>HSR</td><td>Social</td><td>Pair 5</td><td>16, 17</td></tr>
                    </tbody>
                  </table>
                </div>
              </details>
            <!-- end of Setup section -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End experimental setup -->

<!-- Data processing -->
<section class="hero is-small">
   <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Data Pipeline</h2>
      <!-- unordered html list below -->
      <div style="display: flex; gap: 16px; align-items: center;">
        <div style="flex: 1;">
          <!-- add image below-->
          <img src="static/images/robots.jpg" alt="Experimental Setup" style="width: 100%; height: auto; border-radius: 8px;">
        </div>
          <p style="flex: 1;">
            The robots used in the NavWareSet dataset are the
            <a href="https://clearpathrobotics.com/jackal-small-unmanned-ground-vehicle/" target="_blank" style="color: #1a0dab;">Clearpath Jackal</a> and the
            <a href="https://www.toyota-europe.com/news/2018/toyota-expanding-robotics-research-in-europe" target="_blank" style="color: #1a0dab;">Toyota HSR</a>.
            The Jackal is a small, rugged robot designed for outdoor and indoor environments, equipped with a 3D LiDAR sensor and an RGB-D camera.
            The HSR is a versatile human-support robot capable of performing household tasks, featuring a manipulator arm, a mobile base, and various sensors for safe and intelligent interaction with people and objects.
            In most scenarios both robots were teleoperated by a human operator, first in a socially aware manner, and then in a non-aware manner.
          </p>
      </div>
  </div>
</section>
<!-- End Data processing -->

<!-- Data Overview -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Data Overview</h2>
          <!-- add Expandable section below -->
          <details class="expandable">
            <summary> Click to expand</summary>
            <div class="content">
              <p>This is the hidden content that appears when expanded.</p>
            </div>
          </details>
    </div>
  </div>
</section>
<!-- End Data Overview -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
